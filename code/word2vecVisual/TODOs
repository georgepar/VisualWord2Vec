List of todos:

- Read the test and validation files better (solve memory allocation problem) (done)
- Compute the scores for each of test, train. (done)
- Write cross-validation code in C (done)
- Compute the accuracy and match it with matlab accuracies (done)
- Vary learning rate, use differential learning rates (done)
- Vary number of clusters (done)
- Use averaging as opposed to just words (done) (done)
- Can we use just sentences and abstract geometry vectors? (done)
- Regressing with the actual visual vectors - might have to include dropout (defer)
- Use the modified visual features instead of binary (done)
- remove NUM_CLUSTERS (done)
- remove NUM_TRAINING (done)
- remove prs to train (done)
- remove VISUAL_FEATURE_SIZE (done)
- Generalize the last layer (defer)
- Get the numbers for all the various settings (done, multi model left)
- Perform PCA for the visual features before clustering (done, offline, matlab)
- Perform a sweep for various number of clusters (done)
- Train different models for P,R,S (done)
- Keep track of best validation and test accuracies (done)
- Iteration over dataset based on performance on validation set (done)
- Check overfitting based on performance on validation and testing (train and test?) (done)
- Replace total sweep with symmetric sweep in simple cosDist evaluation (done)
- Get the options into command line arguments for faster chain execution (done, modified for now)
- Save the word2vec for different runs for faster chain execution (done)
- Also use Wiki to train word2vec, instead of MS COCO
- Use the new features for training (done)
- Re-compute the scores for all the experiments (done)
- Setup t-SNE embeddings (done)
- Get the embeddings which differ a lot and are positively classified (done)
- Visualize using t-SNE (done)
- Get the plot of accuracy vs amount of training data (done for one model, more below on this)
- Figure out the 0.1% difference from ICCV baseline (done)
- Make the code faster (defer)
- Number of dimensions vs accuracy graph and interpretation (done)
- Plot of accuracy vs number of training instances (done)
- Run Visual + Textual ICCV model (done)
    - Validate single model through matlab code (done)
    - Get the accuracy for multi model through matlab (done)
    - Get the overall Visual + Textual scores for single model (done)
    - Get the overall Visual + Textual scores for multi model (done)
- Vary the number of relations and train the models (done)
- Visualize and reason about the clusters formed initially (done)
    - Get the closest top images for each cluster (done)
    - TSNE for P,R,S based on cluster (done)
    - TSNE for (P,R,S) tuple for each cluster (done)
    - TSNE for visual features (done)

Train VP for scratch:
--------------------
    - Use ms_coco + vp training data together to train visual word2vec (done) - doesn't work well
    - Train visual word2vec from scratch (done)
        - Lemmatize MS COCO for refining (done)
        - Lemmatize abstract training sentences (done)
        - Extract visual features for abstract scenes (done)
        - Refine based on these visual features (done)
    - Dump all VP sentences : sentences_1, sentences_2 (done)
    - Lemmatize them (done)
    - Compute the word2vec features from C (done)
    - Read word2vec features in matlab (done)
    - Confirm the original accuracy with by-pass (done)
    - Get VP into the loop to stop word2vec refining (done)
    - Text alignment for paraphrases 
- Correct P,R,S training data from inflections using inverse map (done)

CVPR:
Run Xiaos Visual paraphrasing(and fitb?) task for text baseline
---------------------------------------------------------------
- Make the code faster (tough to debug otherwise)
- Compute the word overlap statistics for 3-4 separate cases
- Setup system for refining over sentences for VP task (done)

- Reason out why our model works better, intuitively
- Check for pairs whose distance increase/decreased the most
- Check for triplets whose relative distance increased/decreased the most

Visual Paraphrasing
-------------------
- Adjust the learning rates to get a more stable plots (done)
- Train with individual words (done)
- Train on wikipedia and test on VP task (done)
- Run both Xiao's course and fine grain tasks
- Play with parameters to get some sense of graphs
- Hold out a validation set (done)
- Compute overlap statistics
- Setup VQA dataset
