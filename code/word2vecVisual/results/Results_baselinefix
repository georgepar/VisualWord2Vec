Results using correctedFeatures/:
These have real valued location features are not binary.
The race, flip feature extraction bug is also taken care of.
The original word2vec baseline is from xiaos' ICCV
================================================
Sept 28
=======
PCA (374), Individual words, 10 : 
    (73.94, 72.30) => (74.85, 73.50)
PCA (374), Individual words, 15 : 
    (73.94, 72.30) => (75.20, 73.68)
PCA (374), Individual words, 20 : 
    (73.94, 72.30) => (74.78, 73.38)
PCA (374), Individual words, 25 : 
    (73.94, 72.30) => (75.31, 73.93)
PCA (374), Individual words, 30 : 
    (73.94, 72.30) => (75.46, 74.10)
-------------------------------
PCA (374), Phrases, 10 : 
    (73.94, 72.30) => (74.87, 73.46)
PCA (374), Phrases, 15 : 
    (73.94, 72.30) => (74.26, 72.66)
PCA (374), Phrases, 20 : 
    (73.94, 72.30) => (74.24, 72.72)
PCA (374), Phrases, 25 : 
    (73.94, 72.30) => (74.23, 72.74)
PCA (374), Phrases, 30 : 
    (73.94, 72.30) => (74.36, 72.92)
PCA (374), Phrases, 35 : 
    (73.94, 72.30) => (74.02, 72.47)
-------------------------------
1222, Individual words, 10 :
    (73.94, 72.30) => (74.65, 73.20)
1222, Individual words, 15 :
    (73.94, 72.30) => (75.07, 73.62)
1222, Individual words, 20 :
    (73.94, 72.30) => (75.66, 74.26)
1222, Individual words, 25 :
    (73.94, 72.30) => (75.63, 74.20)
1222, Individual words, 30 :
    (73.94, 72.30) => (75.49, 74.11)
-------------------------------
1222, Phrases, 10 : 
    (73.94, 72.30) => (74.11, 72.50)
1222, Phrases, 15 : 
    (73.94, 72.30) => (74.32, 72.88)
1222, Phrases, 20 : 
    (73.94, 72.30) => (74.38, 72.97)
1222, Phrases, 25 : 
    (73.94, 72.30) => (74.63, 73.18)
1222, Phrases, 30 : 
    (73.94, 72.30) => (74.45, 73.02)
================================================
================================================
(Multi models for P,S,R)

PCA (374), Individual words, 5 : 
    (73.94, 72.30) => (73.65, 72.06)
PCA (374), Individual words, 10 : 
    (73.94, 72.30) => (74.95, 73.74)
PCA (374), Individual words, 15 : 
    (73.94, 72.30) => (75.25, 74.02)
PCA (374), Individual words, 20 : 
    (73.94, 72.30) => (75.12, 73.91)
PCA (374), Individual words, 25 : 
    (73.94, 72.30) => (75.55, 74.33)
PCA (374), Individual words, 30 : 
    (73.94, 72.30) => (75.76, 74.57)
-------------------------------
PCA (374), Phrases, 10 : 
    (73.94, 72.30) => (74.81, 73.48)
PCA (374), Phrases, 15 : 
    (73.94, 72.30) => (74.89, 73.40)
PCA (374), Phrases, 20 : 
    (73.94, 72.30) => (74.63, 73.33)
PCA (374), Phrases, 25 : 
    (73.94, 72.30) => (74.00, 72.43)
PCA (374), Phrases, 30 : 
    (73.94, 72.30) => (73.99, 72.38)
-------------------------------
1222, Individual words, 10 :
    (73.94, 72.30) => (74.68, 73.44)
1222, Individual words, 15 :
    (73.94, 72.30) => (75.13, 73.96)
1222, Individual words, 20 :
    (73.94, 72.30) => (75.31, 74.14)
1222, Individual words, 25 :
    (73.94, 72.30) => (75.88, 74.73)
1222, Individual words, 30 :
    (73.94, 72.30) => (75.65, 74.52)
1222, Individual words, 35 :
    (73.94, 72.30) => (75.75, 74.60)
-------------------------------
1222, Phrases, 10 : 
    (73.94, 72.30) => (74.02, 72.40)
1222, Phrases, 15 : 
    (73.94, 72.30) => (74.00, 72.41)
1222, Phrases, 20 : 
    (73.94, 72.30) => (74.01, 72.42)
1222, Phrases, 25 : 
    (73.94, 72.30) => (74.46, 73.15)
1222, Phrases, 30 : 
    (73.94, 72.30) => (74.21, 72.79)
================================================
Accuracy vs amount of training data
----------------------------------
Force number of training data to first N tuples
PCA, multi, 15, Individual words, 

    N = 1000 : 72.30 => 70.63
    N = 2000 : 72.30 => 72.37
    N = 3000 : 72.30 => 73.53
    N = 4000 : 72.30 => 73.83
    N = 4600 : 72.30 => 74.02
================================================
Varying the dimension of the hidden layer
Model : Individual words, Multi, 1222, 25
20: (68.95, 68.01) => (74.14, 73.33)
30: (72.29, 71.09) => (75.67, 74.48)
40: (73.37, 72.18) => (75.81, 74.86)
50: (74.36, 72.89) => (76.53, 75.35)
100: (75.15, 73.53) => (76.47, 74.95)
200: (73.94, 72.30) => (75.88, 74.73)
400: (73.82, 72.33) => (75.29, 73.95)

================================================
Varying the number of training examples per R
Model : Individual words, Multi, 1222, 10
1 : (70.26, 68.24) => (70.30, 68.31)
2: (79.78, 68.66) => (70.64, 68.46)
5 : (72.50, 70.99) => (73.33, 72.08)
10 : (73.32, 71.88) => (74.56, 73.29)
15 : (73.83, 72.18) => (74.48, 73.00)
20 : (73.94, 72.30) => (74.68, 73.44)

12 : (73.74, 72.19) => (74.58, 73.46)
14 : (73.36, 71.82) => (74.34, 73.04)
16 : (73.52, 71.74) => (74.86, 73.37)
18 : (73.81, 72.25) => (74.24, 72.66)
Redo:
14 : (73.65, 72.27) => (74.51, 73.11)
16 : (73.52, 71.74) => (73.91, 72.46)

Model : Individual words, Multi, 1222, 25
1 : (70.26, 68.24) => (70.28, 68.28)
2: (79.78, 68.66) => (70.60, 68.42)
5 : (72.50, 70.99) => (73.38, 70.87)
10 : (73.32, 71.88) => (74.95, 73.61)
15 : (73.83, 72.18) => (75.23, 73.71)
20 : (73.94, 72.30) => (75.88, 74.73)

12: (73.74, 72.19) => (74.96, 73.91)
14 : (73.36, 71.82) => (73.83, 72.74)
16 : (73.52, 71.74) => (73.13, 71.45)
18 : (73.88, 72.25) => (74.66, 73.22)
Redo:
14 : (73.36, 71.82) => (75.11, 74.20)
16 : (73.52, 71.74) => (74.65, 73.31)
18 : (73.88, 72.25) => (74.68, 73.24)

================================================

ICCV (Textual + visual) : 73.62 => 73.90

================================================
Wikipedia text training
1222, Individual Words, Multi
10:
25: (64.41, 63.18) => (74.47, 73.47)
35: 

